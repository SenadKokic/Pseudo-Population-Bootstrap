{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(dplyr) # to use the sample_n function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STAT854: Final Project Code\n",
    "#### Senad Kokic & Zack Huang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we aim to implement the pseudo-population bootstrap proposed by Gross (1980) and Chen et al. (2019). \n",
    "\n",
    "In the naive bootstrap, the first step is as follows (noting a stratified sampling design):\n",
    "\n",
    "- Let $b = 1$. Independently in each of the $H$ strata, draw a simple random sample _with_ replacement of size $n_h$ from the original sample $\\{y_{h1}, \\cdots, y_{h_{n_h}}\\}$ to obtain the bootstrap sample $\\{y_{h1}^{*b}, \\cdots, y_{h_{n_h}}^{*b}\\}$ with corresponding weights $\\{w_{h1}^{*b}, \\cdots, w_{h_{n_h}}^{*b}\\}$\n",
    "\n",
    "This leads to the biased variance estimate, $\\widehat{V}^*(\\bar{y}_{Ha}) = \\frac{1}{B - 1}\\sum_{b = 1}^{B}(\\bar{y}_{Ha}^{*b} - \\bar{y}_{Ha})$.\n",
    "\n",
    "So, the method we employ utilizes sampling _without_ replacement. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also note the assignment information:\n",
    "\n",
    "**Your R code must be a function, where the key arguments are the weights, strata information, and $B$ (the number of bootstrap replicates) and the key output is a matrix/data frame containing the bootstrap weights**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here:\n",
    "- Rescale the weights (if we do not rescale the weights, we will have too many replicates)\n",
    "- Give each column a unique ID for identification (to combine into bootstrap weights later)\n",
    "\n",
    "We also refer to the Assignment 2 file to determine the $N_h$ values for each stratum $h$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# read in the data\n",
    "syc = read.table(\"/Users/senadkokic/Desktop/W2024/STAT 854/Final Project/Data/syc.txt\",\n",
    "            header = T, sep = \",\")\n",
    "# rescale the final weight\n",
    "syc$finalwt = syc$finalwt*(23655/25012)\n",
    "# add a unique ID column for each row\n",
    "ids = seq(from = 1, to = nrow(syc), by = 1)\n",
    "# combine the ID column and the remaining data\n",
    "syc = cbind(ids, syc)\n",
    "# save the Nhs as a vector (from assignment 2 file) for step 2\n",
    "Nhs = c(2724, 3192, 4107, 2705, 3504, 376, 56, 528, 624, 520, 672, 384, 744, 847, 824, 1848)\n",
    "# save the nhs as a vector for step 3\n",
    "nhs = c()\n",
    "for (i in 1:length(unique(syc$stratum))) {\n",
    "    nhs = append(nhs, nrow(syc[syc$stratum == i, ]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we must consider the first step of the process - constructing the fixed part of the pseudo-population, $U^f$. \n",
    "\n",
    "This entails repeating the pair $(y_i, \\pi_i)$ a total of $\\left \\lfloor{\\pi_i^{-1}}\\right \\rfloor$ (i.e. $\\left \\lfloor{w_i}\\right \\rfloor$ times), for all $i \\in S$. For our purposes, this also requires repetition of the ID. \n",
    "\n",
    "However, we ran into mathematical difficulty using the final weights (`finalwt`) as given. So, seeing as we have the appropriate information for $N_h$ and $n_h$, we instead repeat the pair $(y_i, \\pi_i)$ a total of $\\left \\lfloor{\\frac{N_h}{n_h}}\\right \\rfloor$ times.\n",
    "\n",
    "We define a helper function, `construct_fixed_pseudo` to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "construct_fixed_pseudo = function(ids, stratum, weights, Nh, nh) {\n",
    "    # create a blank list for weights, stratum info, and ids\n",
    "    Weights = c()\n",
    "    Stratum = c()\n",
    "    ID = c()\n",
    "    for (i in 1:length(weights)) {\n",
    "        # step 1 - take the floor\n",
    "        num_reps = floor(Nhs[stratum[i]]/nhs[stratum[i]])\n",
    "        # step 2 - replicate each weight, stratum, id num_reps times\n",
    "        reps = rep(weights[i], times = num_reps)\n",
    "        reps_strat = rep(stratum[i], times = num_reps)\n",
    "        reps_id = rep(ids[i], times = num_reps)\n",
    "        # step 3 - add these to the replicates lists\n",
    "        Weights = append(Weights, reps)\n",
    "        Stratum = append(Stratum, reps_strat)\n",
    "        ID = append(ID, reps_id)\n",
    "    }\n",
    "    # return a dataframe of the above\n",
    "    return(data.frame(cbind(ID, Stratum, Weights)))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply checking that the function works as desired. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "fixed_pseudo = construct_fixed_pseudo(syc$ids, syc$stratum, syc$finalwt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we move to the second part of the process - completing the pseudo-population, $U^*$. \n",
    "\n",
    "In this step, we draw $U^{c*}$ from $\\{(y_i, \\pi_i)\\}_{i \\in S}$ using the original sampling design that led to $S$, leading to $U^* = U^f \\cup U^{c*}$. \n",
    "\n",
    "We note that the original survey we are considering, the Survey of Youth in Custody Survey, used a stratified sampling design. In this survey, 16 strata were considered, and the information is given. \n",
    "\n",
    "To determine how many we should be sampling, we consider the difference across each $N_h$ and $\\widehat{N}_h$, where $\\widehat{N}_h$ is the current stratum size in the pseudo-population. We ideally want to sample $N_h -  \\widehat{N}_h < n_h$ from the original sample. \n",
    "\n",
    "Assuming this is stratified simple random sampling, we construct this sample without replacement based on the strata information. To this end, we use a helper function, `construct_stsrswor_pseudo`.\n",
    "\n",
    "Here, we use the `slice_sample` function from the `dplyr` library. It has the same functionality as the `sample` function, however directly returns the samples from the dataframe instead of indices for sampling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "construct_stsrswor_pseudo = function(sample_data, fixed_pseudo_population, stratum_sizes) {\n",
    "    # set data to contain U^c*\n",
    "    Uc = c()\n",
    "    # want to iterate through each stratum\n",
    "    for (strata in 1:length(unique(sample_data$stratum))) {\n",
    "        # retrieve Nh from the stratum sizes\n",
    "        Nh = stratum_sizes[strata]\n",
    "        # determine Nh_hat (the present number of observations in stratum h)\n",
    "        Nh_hat = nrow(fixed_pseudo_population[fixed_pseudo_population$Stratum == strata, ])\n",
    "        # determine how many remain to be sampled \n",
    "        n_r = Nh - Nh_hat\n",
    "        # skip/do not consider if n_r is less than or equal to 0\n",
    "        if (n_r <= 0) next\n",
    "        # now, extract the data from the sample that corresponds to stratum h\n",
    "        strata_data = sample_data[sample_data$stratum == strata, ]\n",
    "        # extract the inclusion probabilities\n",
    "        weights = 1/strata_data$finalwt\n",
    "        # sample from the associated sample stratum\n",
    "        sample = slice_sample(.data = strata_data, n = n_r, replace = FALSE, weight_by = weights)\n",
    "        # combine with the previous samples\n",
    "        Uc = rbind(Uc, sample)\n",
    "    }\n",
    "    # return Uc as the IDs, Stratum, Weights\n",
    "    ID = Uc$ids\n",
    "    Stratum = Uc$stratum\n",
    "    Weights = Uc$finalwt\n",
    "    # make a dataframe\n",
    "    Uc = data.frame(cbind(ID, Stratum, Weights))\n",
    "    return(Uc)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply checking that the function works as desired. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "var_pseudo = construct_stsrswor_pseudo(syc, fixed_pseudo, Nhs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we construct another helper, `combine_pseudo`, to combine the results of the previous two functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "combine_pseudo = function(fixed_pp, var_pp) {\n",
    "    # combine the pseudo-population components\n",
    "    return(rbind(fixed_pp, var_pp))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply checking that the function works as desired. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "pseudo_pop = combine_pseudo(fixed_pseudo, var_pseudo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we consider the third step - being selecting a sample $S^*$ from $U^*$ in the same manner that $S$ was selected from $U$. In our case, this would be using STSRSWOR, sampling $n_h$ units for each stratum $h$. \n",
    "\n",
    "We construct a function, `bootstrap_sample`, to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "bootstrap_sample = function(pseudo_population, nh = nhs) {\n",
    "    # create a list for the combined sample\n",
    "    sample_hs = c()\n",
    "    for (i in 1:length(nh)) {\n",
    "        # selecting the ith strata from the pseudo population for consideration\n",
    "        x = pseudo_population[pseudo_population$Stratum == i, ]\n",
    "        # determine the weights\n",
    "        wts = 1/x$Weights\n",
    "        # select the sample\n",
    "        sample = slice_sample(.data = x, \n",
    "                               n = nhs[i], \n",
    "                               replace = FALSE, \n",
    "                               weight_by = wts)\n",
    "        # attach to the existing overall sample\n",
    "        sample_hs = rbind(sample_hs, sample)\n",
    "    }\n",
    "    return(sample_hs)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply checking that the function works as desired. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "bootstrap_sample(pseudo_pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we put it all together - combining the helper functions into one function to create $B$ bootstrap samples. So, the desired output here is a weight matrix, being 2621x100. \n",
    "\n",
    "In constructing the weight matrix, we recognize the main jist of bootstrapping is the sampling with replacement. We must figure how a boostrap weight, $w_{h_{n_i}}^{*b}$ is constructed.\n",
    "\n",
    "If a sample appears multiple times in the bootstrap, say $t$ times, its weight is $w_{h_{n_i}}^{*b} = tw_{h_{n_i}}$, otherwise, it has a weight of $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "chen_bootstrap = function(ids = syc$ids , # the ID values extracted from the survey file\n",
    "                          stratum = syc$stratum, # the stratum values from the survey file\n",
    "                          weights = syc$finalwt, # weights from the survey file\n",
    "                          Nh = Nhs, # stratum sizes\n",
    "                          nh = nhs, # stratum sample sizes\n",
    "                          sample_data = syc, # sample data\n",
    "                          B = 100) # number of bootstrap replicates\n",
    "{\n",
    "    # create the row names\n",
    "    col_nam = c(\"ID\")\n",
    "    # save a list for the weight matrix: the first column will be the id column\n",
    "    weight_matrix = matrix(nrow = nrow(sample_data), ncol = B)\n",
    "    # creating the fixed part of the pseudo population\n",
    "    fixed_pseudo = construct_fixed_pseudo(ids, stratum, weights)\n",
    "    # create the variable part of the pseudo population\n",
    "    var_pseudo = construct_stsrswor_pseudo(sample_data, fixed_pseudo, Nh)\n",
    "    # combine the two parts of the pseudo population\n",
    "    pseudo_pop = combine_pseudo(fixed_pseudo, var_pseudo)\n",
    "    # now, get the bootstrap weights\n",
    "    for (i in 1:B) {\n",
    "        # create a single bootstrap sample\n",
    "        boot = bootstrap_sample(pseudo_pop)\n",
    "        # now, compute the weights based on the ids\n",
    "        for (id in 1:nrow(sample_data)) {\n",
    "            # if in sample, sum of weights. otherwise, 0\n",
    "            if (id %in% boot$ID) {\n",
    "                weight_matrix[id, i] = sum(boot$Weights[boot$ID == id])\n",
    "            } else {\n",
    "                weight_matrix[id, i] = 0\n",
    "            }\n",
    "        }\n",
    "        # add the corresponding weight vector name to column names\n",
    "        col_nam = append(col_nam, paste(\"w\", i, sep = \"\"))\n",
    "    }\n",
    "    # combine the ids and the weights into a single weight matrix\n",
    "    weight_matrix = cbind(ids, weight_matrix)\n",
    "    # make it a dataframe\n",
    "    weight_df = data.frame(weight_matrix)\n",
    "    # set the column names\n",
    "    colnames(weight_df) = col_nam\n",
    "    return(weight_df)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we finally produce the weight matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# setting a seed\n",
    "set.seed(454854)\n",
    "# call the function \n",
    "weight_df = chen_bootstrap(ids = syc$ids , # the ID values extracted from the survey file\n",
    "                          stratum = syc$stratum, # the stratum values from the survey file\n",
    "                          weights = syc$finalwt, # weights from the survey file\n",
    "                          Nh = Nhs, # stratum sizes\n",
    "                          nh = nhs, # stratum sample sizes\n",
    "                          sample_data = syc, # sample data\n",
    "                          B = 100) # number of bootstrap replicates\n",
    "# write the dataframe to a csv\n",
    "write.csv(weight_df, \n",
    "          file = \"/Users/senadkokic/Desktop/W2024/STAT 854/Final Project/Data/weight_matrix.csv\",\n",
    "          row.names = FALSE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
